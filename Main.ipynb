{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch"
      ],
      "metadata": {
        "id": "XRHFBQBn5LuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch==1.10.2+cu113 torchvision==0.11.3+cu113 torchaudio==0.10.2+cu113 -i https://download.pytorch.org/whl/cu113/"
      ],
      "metadata": {
        "id": "slHOubcB5NiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Need to ensure using torch version 1.10 \n",
        "import torch\n",
        "import torchvision\n",
        "import torchaudio\n",
        "print(torch.__version__, torchvision.__version__, torchaudio.__version__)\n",
        "print(torch.cuda.get_device_name(0), torch.cuda.get_device_capability(0))\n",
        "# x=torch.rand(3,3).to(0)\n",
        "# print(torch.mm(x, torch.inverse(x)))\n",
        "# print(torch.ops.image.decode_png, torch.ops.torchvision.roi_align)"
      ],
      "metadata": {
        "id": "0T7Tuvfh5azx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMjwhNQRkOcl"
      },
      "source": [
        "import pandas as pd\n",
        "import keras\n",
        "import numpy as np\n",
        "import cvxpy as cp\n",
        "from numpy import shape\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "import copy\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.autograd as autograd\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from itertools import accumulate\n",
        "import cvxpy as cp\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-ot9dda7Z7D"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccSB9gzCkOcx"
      },
      "source": [
        "SMALL_SIZE = 16\n",
        "MEDIUM_SIZE = 16\n",
        "BIGGER_SIZE = 16\n",
        "\n",
        "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHqshd7ykOcx"
      },
      "source": [
        "### Load in data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BKtCXJX4OgC"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Demand_household.csv')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSZ59ow04Oit"
      },
      "source": [
        "df = df.drop(columns=['Time', 'Weather'])\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAPGYCTk4OmX"
      },
      "source": [
        "# Assuming same lines from your example\n",
        "cols_to_norm = ['Temp', 'Dew Point Temp', 'Rel Hum', 'Wind Spd', 'Visibility', 'Stn Press']\n",
        "df[cols_to_norm] = df[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTKG1D384OoR"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o37b6PM4gP8"
      },
      "source": [
        "Add in other features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ8p1WPG4c5K"
      },
      "source": [
        "sLength = len(df['Demand'])\n",
        "\n",
        "df['weekend'] = pd.Series(np.random.randn(sLength), index=df.index)\n",
        "df['pre_day'] = pd.Series(np.random.randn(sLength), index=df.index)\n",
        "\n",
        "df['hour_temp'] = pd.Series(np.random.randn(sLength), index=df.index)\n",
        "# df['month_temp'] = pd.Series(np.random.randn(sLength), index=df.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGLlOCd34c7R"
      },
      "source": [
        "for i in range(sLength):\n",
        "    date = int(np.floor(i/24))\n",
        "    hour = i%24\n",
        "    df.at[i, 'Demand'] = df.at[i, 'Demand']/1000 #change demand to Kwh\n",
        "    df.at[i, 'hour_temp'] = hour*df.iloc[i]['Temp']\n",
        "    # df.at[i, 'month_temp'] = df.iloc[i]['Month']*df.iloc[i]['Temp']\n",
        "\n",
        "    if(date%7 == 0 or date%7 == 6):\n",
        "        df.at[i, 'weekend'] = 1\n",
        "    else:\n",
        "        df.at[i, 'weekend'] = 0\n",
        "    \n",
        "    if(i<24):\n",
        "        df.at[i, 'pre_day'] = df.iloc[i]['Demand']\n",
        "    else:\n",
        "        df.at[i, 'pre_day'] = df.iloc[i-24]['Demand']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdcXFJ5V4c9I"
      },
      "source": [
        "df1 = df[df['weekend']==0]\n",
        "df1 = df1.reset_index(drop=True) \n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR2ZPRT74w8Q"
      },
      "source": [
        "Test with sklearn package to see initial baseline load forecast performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-12ukCnI4rkM"
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.neural_network import MLPRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpBzTvVV41r0"
      },
      "source": [
        "X = df[['Temp', 'Rel Hum', 'hour_temp', 'pre_day', 'Month']] #'month_temp', \n",
        "\n",
        "Y = df['Demand']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmQ_dIZw41tr"
      },
      "source": [
        "df_feature = np.zeros((730, 24*4+1))\n",
        "df_bs = np.zeros((730, 24))\n",
        "T = 24"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKDaWNh-41vN"
      },
      "source": [
        "for i in range(730):\n",
        "    df_bs[i,:] = df.iloc[i*T:(i+1)*T]['Demand'].to_numpy()\n",
        "    \n",
        "    df_feature[i, :] = np.concatenate((df.iloc[i*T:(i+1)*T]['Temp'].to_numpy(),\n",
        "                                       df.iloc[i*T:(i+1)*T]['Rel Hum'].to_numpy(),\n",
        "                                       df.iloc[i*T:(i+1)*T]['hour_temp'].to_numpy(),\n",
        "                                      #  df.iloc[i*T:(i+1)*T]['month_temp'].to_numpy(),\n",
        "                                       df.iloc[i*T:(i+1)*T]['pre_day'].to_numpy(),\n",
        "                                       df.iloc[i*T]['Month']), axis=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSZ65jpI49Sz"
      },
      "source": [
        "## correct one data df_feature[10, 46] NaN error\n",
        "df_feature[10, 46] = 0.86419753\n",
        "X_train = df_feature[0:300,:]\n",
        "X_test = df_feature[300:360,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuHXhGlor0t8"
      },
      "source": [
        "np.std(df_bs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZDQab-q49U2"
      },
      "source": [
        "y_train = df_bs[0:300,:]\n",
        "y_test = df_bs[300:360,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmNCSOiz49Wg"
      },
      "source": [
        "regr = MLPRegressor(hidden_layer_sizes=(200, 100, 100), max_iter=500, \n",
        "                    validation_fraction=0.2).fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCGRUqWE49YV"
      },
      "source": [
        "regr.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcfagGBakOc8"
      },
      "source": [
        "df_pred = regr.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTEnJZ1nkOc8"
      },
      "source": [
        "mean_squared_error(y_test, df_pred, squared=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihQXMLqRkOc9"
      },
      "source": [
        "t = 20\n",
        "plt.plot(df_pred[t], label = 'Predicted')\n",
        "plt.plot(y_test[t], label = 'True')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8aB6xqkkOc9"
      },
      "source": [
        "error = df_pred - y_test\n",
        "error = error.reshape((-1, 1))\n",
        "plt.hist(error, bins=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU83bpwvkOc-"
      },
      "source": [
        "np.std(error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6buxjRkq-3Gg"
      },
      "source": [
        "Add in price data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USGL-0f8-6Ps"
      },
      "source": [
        "### load price data\n",
        "t2 = loadmat('/content/drive/My Drive/Colab Notebooks/t2_data.mat')\n",
        "DAP = t2['lambda']\n",
        "\n",
        "N_start = 365*2+31+29+31 #training days\n",
        "N_end = 365*3+31+29+31 #training days\n",
        "\n",
        "T = 24\n",
        "DAP_seg = DAP[N_start*T:N_end*T] #get 2012 NYISO DAP data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwFVKKoxkOdA"
      },
      "source": [
        "### ALL Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNebUcTOkOdA"
      },
      "source": [
        "## Baseline demand forecast module: \n",
        "class LoadForecast(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(LoadForecast, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(input_dim, 2*hidden_dim)\n",
        "        self.linear2 = nn.Linear(2*hidden_dim, hidden_dim)\n",
        "        self.linear3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.linear4 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        output = self.linear4(x)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3nbV1T8kOdB"
      },
      "source": [
        "class OptLayer(nn.Module):\n",
        "    def __init__(self, variables, parameters, objective, inequalities, equalities, **cvxpy_opts):\n",
        "        super().__init__()\n",
        "        self.variables = variables\n",
        "        self.parameters = parameters\n",
        "        self.objective = objective\n",
        "        self.inequalities = inequalities\n",
        "        self.equalities = equalities\n",
        "        self.cvxpy_opts = cvxpy_opts\n",
        "        \n",
        "        # create the cvxpy problem with objective, inequalities, equalities\n",
        "        self.cp_inequalities = [ineq(*variables, *parameters) <= 0 for ineq in inequalities]\n",
        "        self.cp_equalities = [eq(*variables, *parameters) == 0 for eq in equalities]\n",
        "        self.problem = cp.Problem(cp.Minimize(objective(*variables, *parameters)), \n",
        "                                  self.cp_inequalities + self.cp_equalities)\n",
        "        \n",
        "    def forward(self, *batch_params):\n",
        "        out, J = [], []\n",
        "        # solve over minibatch by just iterating\n",
        "        for batch in range(batch_params[0].shape[0]):\n",
        "            # solve the optimization problem and extract solution + dual variables\n",
        "            params = [p[batch] for p in batch_params]\n",
        "            with torch.no_grad():\n",
        "                for i,p in enumerate(self.parameters):\n",
        "                    p.value = params[i].double().numpy()\n",
        "                self.problem.solve(**self.cvxpy_opts)\n",
        "                z = [torch.tensor(v.value).type_as(params[0]) for v in self.variables]\n",
        "                lam = [torch.tensor(c.dual_value).type_as(params[0]) for c in self.cp_inequalities]\n",
        "                nu = [torch.tensor(c.dual_value).type_as(params[0]) for c in self.cp_equalities]\n",
        "\n",
        "            # convenience routines to \"flatten\" and \"unflatten\" (z,lam,nu)\n",
        "            def vec(z, lam, nu):\n",
        "                return torch.cat([a.view(-1) for b in [z,lam,nu] for a in b])\n",
        "\n",
        "            def mat(x):\n",
        "                sz = [0] + list(accumulate([a.numel() for b in [z,lam,nu] for a in b]))\n",
        "                val = [x[a:b] for a,b in zip(sz, sz[1:])]\n",
        "                return ([val[i].view_as(z[i]) for i in range(len(z))],\n",
        "                        [val[i+len(z)].view_as(lam[i]) for i in range(len(lam))],\n",
        "                        [val[i+len(z)+len(lam)].view_as(nu[i]) for i in range(len(nu))])\n",
        "\n",
        "            # computes the KKT residual\n",
        "            def kkt(z, lam, nu, *params):\n",
        "                g = [ineq(*z, *params) for ineq in self.inequalities]\n",
        "                dnu = [eq(*z, *params) for eq in self.equalities]\n",
        "                L = (self.objective(*z, *params) + \n",
        "                     sum((u*v).sum() for u,v in zip(lam,g)) + sum((u*v).sum() for u,v in zip(nu,dnu)))\n",
        "                dz = autograd.grad(L, z, create_graph=True)\n",
        "                dlam = [lam[i]*g[i] for i in range(len(lam))]\n",
        "                return dz, dlam, dnu\n",
        "\n",
        "            # compute residuals and re-engage autograd tape\n",
        "            y = vec(z, lam, nu)\n",
        "            y = y - vec(*kkt([z_.clone().detach().requires_grad_() for z_ in z], lam, nu, *params))\n",
        "\n",
        "            # compute jacobian and backward hook\n",
        "            J.append(autograd.functional.jacobian(lambda x: vec(*kkt(*mat(x), *params)), y))\n",
        "            y.register_hook(lambda grad,b=batch : torch.solve(grad[:,None], J[b].transpose(0,1))[0][:,0])\n",
        "            \n",
        "            out.append(mat(y)[0])\n",
        "        out = [torch.stack(o, dim=0) for o in zip(*out)]\n",
        "        return out[0] if len(out) == 1 else tuple(out)        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN6f9iV_kOdC"
      },
      "source": [
        "class PolytopeProjection(nn.Module):\n",
        "    def __init__(self, d):\n",
        "        super().__init__()\n",
        "        # param: alpha - discomfort utility\n",
        "        # param: N - upperbound\n",
        "        # param: M - lowerbound\n",
        "        self.alpha = nn.Parameter(50*torch.ones(1))\n",
        "        self.N = nn.Parameter(10*torch.ones(1))\n",
        "        self.M = nn.Parameter(-10*torch.ones(1))\n",
        "        \n",
        "        obj = (lambda x, price, alpha, N, M: price@x+0.5*cp.sum_squares(cp.sqrt(alpha)*x) \n",
        "               if isinstance(x, cp.Variable) else price@x+0.5*alpha*torch.sum(x**2))\n",
        "        \n",
        "        ineq1 = lambda x, price, alpha, N, M: torch.ones(T, dtype=torch.double)@x-N\n",
        "        ineq2 = lambda x, price, alpha, N, M: M-torch.ones(T, dtype=torch.double)@x\n",
        "        self.layer = OptLayer([cp.Variable(d)], [cp.Parameter(d), cp.Parameter(1), cp.Parameter(1), cp.Parameter(1)],\n",
        "                              obj, [ineq1, ineq2], [])\n",
        "    \n",
        "    def forward(self, price):\n",
        "        return self.layer(price, self.alpha.expand(price.shape[0], *self.alpha.shape),\n",
        "                          self.N.expand(price.shape[0], *self.N.shape),\n",
        "                          self.M.expand(price.shape[0], *self.M.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWHyjmLBkOdE"
      },
      "source": [
        "def get_batch(X,Y,M):\n",
        "    N = len(Y)\n",
        "    valid_indices = np.array(range(N))\n",
        "    batch_indices = np.random.choice(valid_indices,size=M,replace=False)\n",
        "    batch_xs = X[batch_indices,:]\n",
        "    batch_ys = Y[batch_indices]\n",
        "    return batch_xs, batch_ys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH7jf5h2kOdF"
      },
      "source": [
        "def data_loader(alpha_value, upperbound, lowerbound, DAP_seg, df_bs, N=260, T=24):\n",
        "    \n",
        "    df_price = np.zeros((N, T))\n",
        "    df_dr = np.zeros((N, T))\n",
        "    df_net = np.zeros((N, T))\n",
        "    index = 0\n",
        "    for i in range(N):\n",
        "        price = DAP_seg[i*T:(i+1)*T].reshape(T,)\n",
        "\n",
        "        alpha = alpha_value\n",
        "        N = upperbound\n",
        "        M = lowerbound\n",
        "\n",
        "        # define the user objective function \n",
        "        x = cp.Variable(T)\n",
        "        f = price@x+0.5*alpha*cp.sum_squares(x)\n",
        "        cons = [np.ones(T,)@x <=N, np.ones(T,)@x>=M]\n",
        "        cp.Problem(cp.Minimize(f), cons).solve(verbose=False, eps_abs=1e-8, eps_rel=1e-8)\n",
        "\n",
        "        df_price[index, :] = price.T\n",
        "        df_dr[index, :] = x.value \n",
        "        df_net[index, :] = df_bs[index,:]+df_dr[index, :]\n",
        "\n",
        "        index = index+1\n",
        "    return df_price, df_dr, df_net\n",
        "\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-quM020zkOdG"
      },
      "source": [
        "df_feature = X_train\n",
        "df_bs = y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bupR8ohzkOdI"
      },
      "source": [
        "### Check the OptNet Behavior for Demand Reponse Model Indentification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "446oyn8XkOdI"
      },
      "source": [
        "## data dimension\n",
        "N_train = 200\n",
        "N_test = 60 \n",
        "\n",
        "input_dim = df_feature.shape[1]\n",
        "hidden_dim = 100\n",
        "output_dim = 24\n",
        "print(input_dim, hidden_dim, output_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9WHfLsnkOdI"
      },
      "source": [
        "alpha_value = np.random.uniform(10, 30)\n",
        "bound = np.random.uniform(0, 5)\n",
        "print('Generating the', i, '-th sample!', 'Bound:', bound, 'alpha_value:', alpha_value)\n",
        "\n",
        "df_price, df_dr, df_net = data_loader(alpha_value=alpha_value, upperbound=bound, \n",
        "                                      lowerbound=-bound, DAP_seg=DAP_seg, df_bs=df_bs)\n",
        "\n",
        "price_tensor = torch.from_numpy(df_price)\n",
        "y_tensor = torch.from_numpy(df_dr)\n",
        "\n",
        "# fit demand response from price\n",
        "X_train2_price = price_tensor[0:N_train,:]\n",
        "y_train2 = y_tensor[0:N_train,:]\n",
        "y_train2_noise = y_train2+3.65*torch.randn(N_train, T) \n",
        "\n",
        "# test\n",
        "X_test_price = price_tensor[N_train:N_train+N_test,:]\n",
        "y_test = y_tensor[N_train:N_train+N_test,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNn32KckOdK"
      },
      "source": [
        "M = []\n",
        "M_pred = []\n",
        "alpha = []\n",
        "alpha_pred = [] \n",
        "\n",
        "## Repeat training for N. times in order to get the mean error and std for the results;\n",
        "## Default value: N = 1\n",
        "N = 1\n",
        "for i in range(N):    \n",
        "    alpha_value = np.random.uniform(10, 50)\n",
        "    bound = np.random.uniform(0, 5)\n",
        "    print('Generating the', i, '-th sample!', 'Bound:', bound, 'alpha_value:', alpha_value)\n",
        "\n",
        "    df_price, df_dr, df_net = data_loader(alpha_value=alpha_value, upperbound=bound, \n",
        "                                          lowerbound=-bound, DAP_seg=DAP_seg, df_bs=df_bs)\n",
        "\n",
        "    price_tensor = torch.from_numpy(df_price)\n",
        "    y_tensor = torch.from_numpy(df_dr)\n",
        "\n",
        "    # fit demand response from price\n",
        "    X_train2_price = price_tensor[0:N_train,:]\n",
        "    y_train2 = y_tensor[0:N_train,:]\n",
        "\n",
        "    # Define model and optimizer\n",
        "    torch.manual_seed(0)\n",
        "    layer = PolytopeProjection(d = 24)\n",
        "    opt1 = optim.Adam(layer.parameters(), lr=5e-1)\n",
        "\n",
        "    for ite in range(500):\n",
        "        if(ite == 30):\n",
        "            opt1.param_groups[0][\"lr\"] = 1e-1\n",
        "\n",
        "        dr_pred = layer(X_train2_price)\n",
        "\n",
        "        loss = nn.MSELoss()(y_train2, dr_pred)\n",
        "        opt1.zero_grad()\n",
        "        loss.backward()\n",
        "        opt1.step()\n",
        "        \n",
        "        if(ite%100 == 0):\n",
        "            print(ite)\n",
        "            print('Loss', loss.detach())\n",
        "            print('layer.alpha.gradient =', layer.alpha.grad, 'alpha value =', layer.alpha.detach().numpy())\n",
        "            print('layer.M.gradient =', layer.M.grad, 'M value =', layer.M.detach().numpy())\n",
        "            print('layer.N.gradient =', layer.N.grad)\n",
        "\n",
        "    M.append(-bound)\n",
        "    M_pred.append(layer.M.detach().numpy())\n",
        "    alpha.append(alpha_value)\n",
        "    alpha_pred.append(layer.alpha.detach().numpy())\n",
        "    \n",
        "    print('alpha True:', alpha_value, 'Forecast:', layer.alpha.detach().numpy())\n",
        "    print('M True:', -bound, 'Forecast:', layer.M.detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDSPA0lykOdL"
      },
      "source": [
        "# test on test data set\n",
        "ytest_pred = layer(X_test_price)\n",
        "ytest_pred_np = ytest_pred.detach().numpy().reshape(N_test*T)\n",
        "ytest_np = y_test.detach().numpy().reshape(N_test*T)\n",
        "\n",
        "print('DR forecast Percentage Error', np.mean(abs((ytest_pred_np-ytest_np)/ytest_np)))\n",
        "print('DR forecast RMSE', np.sqrt(np.sum((ytest_pred_np-ytest_np)**2)/N_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhWi-lEJkOdL"
      },
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "# plt.plot(demand_sample, 'b', label = 'Original')\n",
        "plt.plot(ytest_np[0:120], 'g', label = 'DR True')\n",
        "plt.plot(ytest_pred_np[0:120], 'r--', label = 'DR Forecast')\n",
        "plt.grid()\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.xlabel('Time (h)')\n",
        "plt.xlim([0, 120])\n",
        "plt.ylabel('Demand (MW)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('DR_5day.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTCohcFGkOdN"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lXJSMynkOdN"
      },
      "source": [
        "### Warm start with end-to-end training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oenjvSgPkOdO"
      },
      "source": [
        "N_train1 = 200 #pre-train base load module\n",
        "N_train2 = 200 #e2e training\n",
        "N_train = 200\n",
        "N_test = 60 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkHLAmQ6kOdO"
      },
      "source": [
        "# data for baseline demand training\n",
        "Feature_tensor = torch.from_numpy(df_feature).float()\n",
        "Baseline_tensor = torch.from_numpy(df_bs).float()\n",
        "\n",
        "X_train1 = Feature_tensor[0:N_train1,:]\n",
        "y_train1 = Baseline_tensor[0:N_train1,:]\n",
        "\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S0z6n2SFs3T"
      },
      "source": [
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") \n",
        "\n",
        "# define load forecast network\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# load forecast layer\n",
        "load_net = LoadForecast(input_dim=input_dim, hidden_dim=200, output_dim=output_dim).to(device)\n",
        "\n",
        "opt2 = optim.Adam(load_net.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SQctux-C7Zz"
      },
      "source": [
        "## warm start: baseline load model\n",
        "for ite in range(600):\n",
        "    running_loss = 0.0\n",
        "    batch_xs, batch_ys = get_batch(X_train1, y_train1, M = 64)\n",
        "    batch_xs = batch_xs.to(device)\n",
        "    batch_ys = batch_ys.to(device)\n",
        "    batch_pred = load_net(batch_xs)\n",
        "    loss = criterion(batch_ys, batch_pred)\n",
        "    opt2.zero_grad()\n",
        "    loss.backward()\n",
        "    opt2.step()\n",
        "    \n",
        "    if(ite>250):\n",
        "        opt2.param_groups[0][\"lr\"] = 0.0001\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if ite % 50 == 0:    # print every 2000 mini-batches\n",
        "        print('[%5d] loss: %.3f' %\n",
        "              (ite + 1, running_loss / 200))\n",
        "        running_loss = 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC9aAjukGzlo"
      },
      "source": [
        "## make the load forecast module is unbias\n",
        "# baseline_pred = load_net(X_train1.to(device))\n",
        "# baseline_pred_bias = np.mean(np.sum(y_train1[0:200].detach().numpy() - baseline_pred[0:200].detach().cpu().numpy(), axis = 1))\n",
        "# baseline_pred_bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI4oewGUkOdR"
      },
      "source": [
        "M = []\n",
        "M_pred = []\n",
        "alpha = []\n",
        "alpha_pred = [] \n",
        "\n",
        "## Repeat training for N. times in order to get the mean error and std for the results;\n",
        "## Default value: N = 1\n",
        "N = 1\n",
        "for i in range(N):\n",
        "  # data for e2e dr identification\n",
        "  bound = np.random.uniform(1, 10) #2\n",
        "  alpha_value = np.random.uniform(10, 50) #20\n",
        "  print('Generating DR agent model!', 'M_value:', bound, 'alpha_value:', alpha_value)\n",
        "\n",
        "  baseline_load_per1, baseline_feature_per1 = unison_shuffled_copies(df_bs[0:N_train2], df_feature[0:N_train2])\n",
        "\n",
        "  df_price1, df_dr1, df_net1 = data_loader(alpha_value=alpha_value, upperbound=bound, \n",
        "                                          lowerbound=-bound, DAP_seg=DAP_seg, df_bs=baseline_load_per1, N = N_train2)\n",
        "\n",
        "  baseline_tensor = torch.from_numpy(baseline_load_per1).float().to(device)\n",
        "  fea_tensor = torch.from_numpy(baseline_feature_per1).float().to(device)\n",
        "  price_tensor = torch.from_numpy(df_price1)\n",
        "  net_tensor = torch.from_numpy(df_net1).to(device)\n",
        "  dr_tensor = torch.from_numpy(df_dr1).to(device)\n",
        "  \n",
        "  #define implicit layer model\n",
        "  torch.manual_seed(0)\n",
        "  layer = PolytopeProjection(d = 24)\n",
        "  opt1 = optim.Adam(layer.parameters(), lr=0.1)\n",
        "  epst1 = time.time()\n",
        "  for ite in range(500):\n",
        "      # define e2e training\n",
        "      dr_pred = layer(price_tensor)\n",
        "      baseline_pred = load_net(fea_tensor)\n",
        "      net_pred = baseline_pred+dr_pred.to(device)\n",
        "      loss = nn.MSELoss()(net_tensor, net_pred)\n",
        "      opt1.zero_grad()\n",
        "      opt2.zero_grad()\n",
        "      loss.backward()\n",
        "      opt1.step()\n",
        "      if(ite%50 == 0):\n",
        "        opt2.step()\n",
        "\n",
        "      if(ite == 300):\n",
        "          opt1.param_groups[0][\"lr\"] = 5e-2\n",
        "\n",
        "      if(ite%50 == 0):\n",
        "          print(ite)\n",
        "          print('Loss', loss.detach())\n",
        "          print('layer.alpha.gradient =', layer.alpha.grad, 'alpha value =', layer.alpha.detach().cpu().numpy())\n",
        "          print('layer.M.gradient =', layer.M.grad, 'M value =', layer.M.detach().cpu().numpy())\n",
        "  \n",
        "  epst2 = time.time()\n",
        "  print('Training time / 500 epoch', epst2-epst1)     \n",
        "  M.append(-bound)\n",
        "  M_pred.append(layer.M.detach().cpu().numpy())\n",
        "  alpha.append(alpha_value)\n",
        "  alpha_pred.append(layer.alpha.detach().cpu().numpy())\n",
        "\n",
        "  print('alpha True:', alpha_value, 'Forecast:', layer.alpha.detach().cpu().numpy())\n",
        "  print('M True:', -bound, 'Forecast:', layer.M.detach().cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(epst2-epst1)/500"
      ],
      "metadata": {
        "id": "8x7hSir5TsZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## time prediction time\n",
        "epst3 = time.time()\n",
        "dr_pred = layer(price_tensor)\n",
        "baseline_pred = load_net(fea_tensor)\n",
        "net_pred = baseline_pred+dr_pred.to(device)\n",
        "\n",
        "epst4 = time.time()\n",
        "print('Prediction time:', (epst4-epst3)/N_train)"
      ],
      "metadata": {
        "id": "tZ1Axu9vR-Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfFDK6c2kOdb"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vaw7if6ekOdc"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3N5lig0kOdd"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLOTNR7kkOdd"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}